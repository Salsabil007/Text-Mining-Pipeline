{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NI1t86uZAqpj"
   },
   "source": [
    "## 1 Set up Environment in Google Colab\n",
    "\n",
    "Run the following cells to install/upgrade the required packages and check if the installed versions meet the requirements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import feature_selection\n",
    "import copy as cp\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "import sklearn.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "fA2P2alFAt8d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk==3.6.7 in /home/arabi/anaconda3/lib/python3.8/site-packages (3.6.7)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /home/arabi/anaconda3/lib/python3.8/site-packages (from nltk==3.6.7) (2022.1.18)\n",
      "Requirement already satisfied: joblib in /home/arabi/anaconda3/lib/python3.8/site-packages (from nltk==3.6.7) (1.0.1)\n",
      "Requirement already satisfied: tqdm in /home/arabi/anaconda3/lib/python3.8/site-packages (from nltk==3.6.7) (4.59.0)\n",
      "Requirement already satisfied: click in /home/arabi/anaconda3/lib/python3.8/site-packages (from nltk==3.6.7) (7.1.2)\n",
      "Requirement already satisfied: spacy==3.2.1 in /home/arabi/anaconda3/lib/python3.8/site-packages (3.2.1)\n",
      "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /home/arabi/anaconda3/lib/python3.8/site-packages (from spacy==3.2.1) (0.4.0)\n",
      "Requirement already satisfied: setuptools in /home/arabi/anaconda3/lib/python3.8/site-packages (from spacy==3.2.1) (52.0.0.post20210125)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /home/arabi/anaconda3/lib/python3.8/site-packages (from spacy==3.2.1) (3.3.0)\n",
      "Requirement already satisfied: thinc<8.1.0,>=8.0.12 in /home/arabi/anaconda3/lib/python3.8/site-packages (from spacy==3.2.1) (8.0.13)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in /home/arabi/anaconda3/lib/python3.8/site-packages (from spacy==3.2.1) (0.9.0)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /home/arabi/anaconda3/lib/python3.8/site-packages (from spacy==3.2.1) (1.0.1)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /home/arabi/anaconda3/lib/python3.8/site-packages (from spacy==3.2.1) (1.0.6)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/arabi/anaconda3/lib/python3.8/site-packages (from spacy==3.2.1) (20.9)\n",
      "Requirement already satisfied: pathy>=0.3.5 in /home/arabi/anaconda3/lib/python3.8/site-packages (from spacy==3.2.1) (0.6.1)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /home/arabi/anaconda3/lib/python3.8/site-packages (from spacy==3.2.1) (2.0.6)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /home/arabi/anaconda3/lib/python3.8/site-packages (from spacy==3.2.1) (2.25.1)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /home/arabi/anaconda3/lib/python3.8/site-packages (from spacy==3.2.1) (2.0.6)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.1 in /home/arabi/anaconda3/lib/python3.8/site-packages (from spacy==3.2.1) (2.4.2)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /home/arabi/anaconda3/lib/python3.8/site-packages (from spacy==3.2.1) (4.59.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in /home/arabi/anaconda3/lib/python3.8/site-packages (from spacy==3.2.1) (1.8.2)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /home/arabi/anaconda3/lib/python3.8/site-packages (from spacy==3.2.1) (1.20.1)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /home/arabi/anaconda3/lib/python3.8/site-packages (from spacy==3.2.1) (3.0.6)\n",
      "Requirement already satisfied: jinja2 in /home/arabi/anaconda3/lib/python3.8/site-packages (from spacy==3.2.1) (2.11.3)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /home/arabi/anaconda3/lib/python3.8/site-packages (from spacy==3.2.1) (0.7.5)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.8 in /home/arabi/anaconda3/lib/python3.8/site-packages (from spacy==3.2.1) (3.0.8)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /home/arabi/anaconda3/lib/python3.8/site-packages (from packaging>=20.0->spacy==3.2.1) (2.4.7)\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in /home/arabi/anaconda3/lib/python3.8/site-packages (from pathy>=0.3.5->spacy==3.2.1) (5.2.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/arabi/anaconda3/lib/python3.8/site-packages (from pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4->spacy==3.2.1) (3.7.4.3)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /home/arabi/anaconda3/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy==3.2.1) (4.0.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/arabi/anaconda3/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy==3.2.1) (1.26.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/arabi/anaconda3/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy==3.2.1) (2020.12.5)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /home/arabi/anaconda3/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy==3.2.1) (2.10)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /home/arabi/anaconda3/lib/python3.8/site-packages (from typer<0.5.0,>=0.3.0->spacy==3.2.1) (7.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /home/arabi/anaconda3/lib/python3.8/site-packages (from jinja2->spacy==3.2.1) (1.1.1)\n",
      "Collecting scikit-learn==0.24.2\n",
      "  Downloading scikit_learn-0.24.2-cp38-cp38-manylinux2010_x86_64.whl (24.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 24.9 MB 5.4 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: joblib>=0.11 in /home/arabi/anaconda3/lib/python3.8/site-packages (from scikit-learn==0.24.2) (1.0.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/arabi/anaconda3/lib/python3.8/site-packages (from scikit-learn==0.24.2) (2.1.0)\n",
      "Requirement already satisfied: scipy>=0.19.1 in /home/arabi/anaconda3/lib/python3.8/site-packages (from scikit-learn==0.24.2) (1.6.2)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /home/arabi/anaconda3/lib/python3.8/site-packages (from scikit-learn==0.24.2) (1.20.1)\n",
      "Installing collected packages: scikit-learn\n",
      "  Attempting uninstall: scikit-learn\n",
      "    Found existing installation: scikit-learn 0.24.1\n",
      "    Uninstalling scikit-learn-0.24.1:\n",
      "      Successfully uninstalled scikit-learn-0.24.1\n",
      "Successfully installed scikit-learn-0.24.2\n",
      "Collecting en-core-web-sm==3.2.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.2.0/en_core_web_sm-3.2.0-py3-none-any.whl (13.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 13.9 MB 4.4 MB/s eta 0:00:01    |███████████████▋                | 6.8 MB 1.5 MB/s eta 0:00:05\n",
      "\u001b[?25hRequirement already satisfied: spacy<3.3.0,>=3.2.0 in /home/arabi/anaconda3/lib/python3.8/site-packages (from en-core-web-sm==3.2.0) (3.2.1)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /home/arabi/anaconda3/lib/python3.8/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (1.0.1)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.8 in /home/arabi/anaconda3/lib/python3.8/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (3.0.8)\n",
      "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /home/arabi/anaconda3/lib/python3.8/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (0.4.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /home/arabi/anaconda3/lib/python3.8/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2.25.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/arabi/anaconda3/lib/python3.8/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (20.9)\n",
      "Requirement already satisfied: setuptools in /home/arabi/anaconda3/lib/python3.8/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (52.0.0.post20210125)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /home/arabi/anaconda3/lib/python3.8/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (3.3.0)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /home/arabi/anaconda3/lib/python3.8/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (1.0.6)\n",
      "Requirement already satisfied: pathy>=0.3.5 in /home/arabi/anaconda3/lib/python3.8/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (0.6.1)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /home/arabi/anaconda3/lib/python3.8/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2.0.6)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in /home/arabi/anaconda3/lib/python3.8/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (1.8.2)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /home/arabi/anaconda3/lib/python3.8/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (0.7.5)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /home/arabi/anaconda3/lib/python3.8/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (1.20.1)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /home/arabi/anaconda3/lib/python3.8/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (4.59.0)\n",
      "Requirement already satisfied: jinja2 in /home/arabi/anaconda3/lib/python3.8/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2.11.3)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /home/arabi/anaconda3/lib/python3.8/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2.0.6)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in /home/arabi/anaconda3/lib/python3.8/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (0.9.0)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /home/arabi/anaconda3/lib/python3.8/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (3.0.6)\n",
      "Requirement already satisfied: thinc<8.1.0,>=8.0.12 in /home/arabi/anaconda3/lib/python3.8/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (8.0.13)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.1 in /home/arabi/anaconda3/lib/python3.8/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2.4.2)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /home/arabi/anaconda3/lib/python3.8/site-packages (from packaging>=20.0->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2.4.7)\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in /home/arabi/anaconda3/lib/python3.8/site-packages (from pathy>=0.3.5->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (5.2.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/arabi/anaconda3/lib/python3.8/site-packages (from pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (3.7.4.3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: chardet<5,>=3.0.2 in /home/arabi/anaconda3/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (4.0.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /home/arabi/anaconda3/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/arabi/anaconda3/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (1.26.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/arabi/anaconda3/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2020.12.5)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /home/arabi/anaconda3/lib/python3.8/site-packages (from typer<0.5.0,>=0.3.0->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (7.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /home/arabi/anaconda3/lib/python3.8/site-packages (from jinja2->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (1.1.1)\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "# make sure the required python packages are installed\n",
    "\n",
    "# install nltk (we'll use 3.6.7 in Spring 2022)\n",
    "!pip install nltk==3.6.7 --upgrade\n",
    "\n",
    "# install spacy (we'll use 3.2.1 in Spring 2022)\n",
    "!pip install spacy==3.2.1 --upgrade\n",
    "\n",
    "# upgrade scikit-learn 0.24.2\n",
    "!pip install scikit-learn==0.24.2 --upgrade\n",
    "\n",
    "# download the spacy en_core_web_sm model (3.2.0 version)\n",
    "!python -m spacy download en_core_web_sm-3.2.0 --direct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HsMJNcX4QLAR"
   },
   "source": [
    "## 2 Explore the Dataset by Pang et al. (2002)\n",
    "\n",
    "Download the raw dataset at:\n",
    "http://www.cs.cornell.edu/people/pabo/movie-review-data/mix20_rand700_tokens.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "ZFGRjltDNH4O"
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "import sklearn\n",
    "import sklearn.metrics\n",
    "from collections import Counter, OrderedDict\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "nlp = spacy.load( \"en_core_web_sm\", disable=[\"parser\", \"ner\"] )\n",
    "\n",
    "# please use this function to get unigram features\n",
    "def text2unigrams( rawtext, nlp ):\n",
    "    return [ '[OOV]' if token.is_stop or token.is_punct else token.lemma_.lower() for token in nlp(rawtext) ]\n",
    "\n",
    "# please use this function to get bigram features\n",
    "def unigrams2bigrams( unigrams ):\n",
    "    return [ unigrams[i]+'_'+unigrams[i+1] for i in range(len(unigrams)-1) if unigrams[i]!='[OOV]' and unigrams[i+1]!='[OOV]' ]\n",
    "\n",
    "def unigramsplusbigrams( unigrams ):\n",
    "    return unigrams+[ unigrams[i]+'_'+unigrams[i+1] for i in range(len(unigrams)-1) if unigrams[i]!='[OOV]' and unigrams[i+1]!='[OOV]' ]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "8o1FLt-fNH6q"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fold</th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>unigrams</th>\n",
       "      <th>bigrams</th>\n",
       "      <th>unibigrams</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>cv004_tok-29856.txt</th>\n",
       "      <td>1</td>\n",
       "      <td>pos</td>\n",
       "      <td>all great things come to an end , and the dot-...</td>\n",
       "      <td>[[OOV], great, thing, come, [OOV], [OOV], end,...</td>\n",
       "      <td>[great_thing, thing_come, com_era, era_embody,...</td>\n",
       "      <td>[[OOV], great, thing, come, [OOV], [OOV], end,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cv409_tok-11193.txt</th>\n",
       "      <td>2</td>\n",
       "      <td>pos</td>\n",
       "      <td>i'm not quite sure how best to go about writin...</td>\n",
       "      <td>[[OOV], [OOV], [OOV], [OOV], sure, [OOV], good...</td>\n",
       "      <td>[little_disappointed, barry_levinson, politica...</td>\n",
       "      <td>[[OOV], [OOV], [OOV], [OOV], sure, [OOV], good...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cv045_tok-29121.txt</th>\n",
       "      <td>1</td>\n",
       "      <td>pos</td>\n",
       "      <td>the others ( 2001 ) nicole kidman , christophe...</td>\n",
       "      <td>[[OOV], [OOV], [OOV], 2001, [OOV], nicole, kid...</td>\n",
       "      <td>[nicole_kidman, christopher_eccleston, fionnul...</td>\n",
       "      <td>[[OOV], [OOV], [OOV], 2001, [OOV], nicole, kid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cv279_tok-15969.txt</th>\n",
       "      <td>2</td>\n",
       "      <td>pos</td>\n",
       "      <td>director : tony scott writer : david marconi s...</td>\n",
       "      <td>[director, [OOV], tony, scott, writer, [OOV], ...</td>\n",
       "      <td>[tony_scott, scott_writer, david_marconi, marc...</td>\n",
       "      <td>[director, [OOV], tony, scott, writer, [OOV], ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cv387_tok-4672.txt</th>\n",
       "      <td>2</td>\n",
       "      <td>pos</td>\n",
       "      <td>one of the most entertaining james bond films ...</td>\n",
       "      <td>[[OOV], [OOV], [OOV], [OOV], entertaining, jam...</td>\n",
       "      <td>[entertaining_james, james_bond, bond_film, ro...</td>\n",
       "      <td>[[OOV], [OOV], [OOV], [OOV], entertaining, jam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cv562_tok-26379.txt</th>\n",
       "      <td>3</td>\n",
       "      <td>neg</td>\n",
       "      <td>directed by : jan de bont written by : david s...</td>\n",
       "      <td>[direct, [OOV], [OOV], jan, de, bont, write, [...</td>\n",
       "      <td>[jan_de, de_bont, bont_write, david_shelf, shi...</td>\n",
       "      <td>[direct, [OOV], [OOV], jan, de, bont, write, [...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cv000_tok-9611.txt</th>\n",
       "      <td>1</td>\n",
       "      <td>neg</td>\n",
       "      <td>tristar / 1 : 30 / 1997 / r ( language , viole...</td>\n",
       "      <td>[tristar, [OOV], 1, [OOV], 30, [OOV], 1997, [O...</td>\n",
       "      <td>[dennis_rodman, claude_van, van_damme, mickey_...</td>\n",
       "      <td>[tristar, [OOV], 1, [OOV], 30, [OOV], 1997, [O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cv571_tok-11568.txt</th>\n",
       "      <td>3</td>\n",
       "      <td>neg</td>\n",
       "      <td>director : michael caton-jones writer : chuck ...</td>\n",
       "      <td>[director, [OOV], michael, caton, [OOV], jones...</td>\n",
       "      <td>[michael_caton, jones_writer, chuck_pfarrer, k...</td>\n",
       "      <td>[director, [OOV], michael, caton, [OOV], jones...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cv210_tok-15092.txt</th>\n",
       "      <td>1</td>\n",
       "      <td>neg</td>\n",
       "      <td>wrongfully accused reviewed by jamie peck&lt;hr&gt;r...</td>\n",
       "      <td>[wrongfully, accuse, review, [OOV], jamie, pec...</td>\n",
       "      <td>[wrongfully_accuse, accuse_review, jamie_peck,...</td>\n",
       "      <td>[wrongfully, accuse, review, [OOV], jamie, pec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cv629_tok-26880.txt</th>\n",
       "      <td>3</td>\n",
       "      <td>neg</td>\n",
       "      <td>throw some shots of a vaguely menacing fetus o...</td>\n",
       "      <td>[throw, [OOV], shot, [OOV], [OOV], vaguely, me...</td>\n",
       "      <td>[vaguely_menacing, menacing_fetus, opening_cre...</td>\n",
       "      <td>[throw, [OOV], shot, [OOV], [OOV], vaguely, me...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1400 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     fold label  \\\n",
       "cv004_tok-29856.txt     1   pos   \n",
       "cv409_tok-11193.txt     2   pos   \n",
       "cv045_tok-29121.txt     1   pos   \n",
       "cv279_tok-15969.txt     2   pos   \n",
       "cv387_tok-4672.txt      2   pos   \n",
       "...                   ...   ...   \n",
       "cv562_tok-26379.txt     3   neg   \n",
       "cv000_tok-9611.txt      1   neg   \n",
       "cv571_tok-11568.txt     3   neg   \n",
       "cv210_tok-15092.txt     1   neg   \n",
       "cv629_tok-26880.txt     3   neg   \n",
       "\n",
       "                                                                  text  \\\n",
       "cv004_tok-29856.txt  all great things come to an end , and the dot-...   \n",
       "cv409_tok-11193.txt  i'm not quite sure how best to go about writin...   \n",
       "cv045_tok-29121.txt  the others ( 2001 ) nicole kidman , christophe...   \n",
       "cv279_tok-15969.txt  director : tony scott writer : david marconi s...   \n",
       "cv387_tok-4672.txt   one of the most entertaining james bond films ...   \n",
       "...                                                                ...   \n",
       "cv562_tok-26379.txt  directed by : jan de bont written by : david s...   \n",
       "cv000_tok-9611.txt   tristar / 1 : 30 / 1997 / r ( language , viole...   \n",
       "cv571_tok-11568.txt  director : michael caton-jones writer : chuck ...   \n",
       "cv210_tok-15092.txt  wrongfully accused reviewed by jamie peck<hr>r...   \n",
       "cv629_tok-26880.txt  throw some shots of a vaguely menacing fetus o...   \n",
       "\n",
       "                                                              unigrams  \\\n",
       "cv004_tok-29856.txt  [[OOV], great, thing, come, [OOV], [OOV], end,...   \n",
       "cv409_tok-11193.txt  [[OOV], [OOV], [OOV], [OOV], sure, [OOV], good...   \n",
       "cv045_tok-29121.txt  [[OOV], [OOV], [OOV], 2001, [OOV], nicole, kid...   \n",
       "cv279_tok-15969.txt  [director, [OOV], tony, scott, writer, [OOV], ...   \n",
       "cv387_tok-4672.txt   [[OOV], [OOV], [OOV], [OOV], entertaining, jam...   \n",
       "...                                                                ...   \n",
       "cv562_tok-26379.txt  [direct, [OOV], [OOV], jan, de, bont, write, [...   \n",
       "cv000_tok-9611.txt   [tristar, [OOV], 1, [OOV], 30, [OOV], 1997, [O...   \n",
       "cv571_tok-11568.txt  [director, [OOV], michael, caton, [OOV], jones...   \n",
       "cv210_tok-15092.txt  [wrongfully, accuse, review, [OOV], jamie, pec...   \n",
       "cv629_tok-26880.txt  [throw, [OOV], shot, [OOV], [OOV], vaguely, me...   \n",
       "\n",
       "                                                               bigrams  \\\n",
       "cv004_tok-29856.txt  [great_thing, thing_come, com_era, era_embody,...   \n",
       "cv409_tok-11193.txt  [little_disappointed, barry_levinson, politica...   \n",
       "cv045_tok-29121.txt  [nicole_kidman, christopher_eccleston, fionnul...   \n",
       "cv279_tok-15969.txt  [tony_scott, scott_writer, david_marconi, marc...   \n",
       "cv387_tok-4672.txt   [entertaining_james, james_bond, bond_film, ro...   \n",
       "...                                                                ...   \n",
       "cv562_tok-26379.txt  [jan_de, de_bont, bont_write, david_shelf, shi...   \n",
       "cv000_tok-9611.txt   [dennis_rodman, claude_van, van_damme, mickey_...   \n",
       "cv571_tok-11568.txt  [michael_caton, jones_writer, chuck_pfarrer, k...   \n",
       "cv210_tok-15092.txt  [wrongfully_accuse, accuse_review, jamie_peck,...   \n",
       "cv629_tok-26880.txt  [vaguely_menacing, menacing_fetus, opening_cre...   \n",
       "\n",
       "                                                            unibigrams  \n",
       "cv004_tok-29856.txt  [[OOV], great, thing, come, [OOV], [OOV], end,...  \n",
       "cv409_tok-11193.txt  [[OOV], [OOV], [OOV], [OOV], sure, [OOV], good...  \n",
       "cv045_tok-29121.txt  [[OOV], [OOV], [OOV], 2001, [OOV], nicole, kid...  \n",
       "cv279_tok-15969.txt  [director, [OOV], tony, scott, writer, [OOV], ...  \n",
       "cv387_tok-4672.txt   [[OOV], [OOV], [OOV], [OOV], entertaining, jam...  \n",
       "...                                                                ...  \n",
       "cv562_tok-26379.txt  [direct, [OOV], [OOV], jan, de, bont, write, [...  \n",
       "cv000_tok-9611.txt   [tristar, [OOV], 1, [OOV], 30, [OOV], 1997, [O...  \n",
       "cv571_tok-11568.txt  [director, [OOV], michael, caton, [OOV], jones...  \n",
       "cv210_tok-15092.txt  [wrongfully, accuse, review, [OOV], jamie, pec...  \n",
       "cv629_tok-26880.txt  [throw, [OOV], shot, [OOV], [OOV], vaguely, me...  \n",
       "\n",
       "[1400 rows x 6 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv( 'pang2002.csv', index_col=0 )\n",
    "\n",
    "data['unigrams'] = [ text2unigrams(text, nlp) for text in data['text'] ]\n",
    "data['bigrams'] = [ unigrams2bigrams(unigrams) for unigrams in data['unigrams'] ]\n",
    "data['unibigrams'] = [ unigramsplusbigrams(unigrams) for unigrams in data['unigrams'] ]\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "ge6DrQnsay9_"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "466   466   468\n",
      "0.7685399166085861   0.7956788085543449   0.7035508602032207   0.6971130919628773   0.7756838218211609   0.797833901911155\n",
      "           Features Fres./Pres.  Accuracy  My Accuracy\n",
      "0          Unigrams        Fres    0.7728     0.768540\n",
      "1          Unigrams        Pres    0.7893     0.795679\n",
      "2           Bigrams        Fres    0.7036     0.703551\n",
      "3           Bigrams        Pres    0.6885     0.697113\n",
      "4  Unigrams+Bigrams        Fres    0.7742     0.775684\n",
      "5  Unigrams+Bigrams        Pres    0.7971     0.797834\n"
     ]
    }
   ],
   "source": [
    "#Settings 1\n",
    "##divide into k fold\n",
    "fold1 = data[data.fold == 1]\n",
    "fold2 = data[data.fold == 2]\n",
    "fold3 = data[data.fold == 3]\n",
    "print(len(fold1),\" \",len(fold2),\" \",len(fold3))\n",
    "\n",
    "def prepareDataset(data, dict, updateDict,TEXT):\n",
    "    X = dict.fit_transform( Counter(text) for text in data[TEXT] ) if updateDict else dict.transform( Counter(text) for text in data[TEXT] )\n",
    "    Y = np.array(data['label'])\n",
    "    return X, Y\n",
    "\n",
    "\n",
    "def select_dict( dict, top, X, Y ):\n",
    "    top = min( top, X.shape[1] )\n",
    "    fsel = feature_selection.SelectKBest( score_func = feature_selection.chi2, k = top )\n",
    "    X_selected = fsel.fit_transform( X, Y )\n",
    "    dict_selected = cp.deepcopy(dict).restrict( fsel.get_support() )\n",
    "    return dict_selected, X_selected\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def accuracy(trn,test,label,freq,n):\n",
    "    dict = DictVectorizer()\n",
    "    training_X, training_Y = prepareDataset(trn, dict, updateDict=True, TEXT=label)\n",
    "    #a = pd.DataFrame( training_X.toarray(), columns = dict.get_feature_names() )\n",
    "    top = int(n)\n",
    "    dict_selected, training_X_selected = select_dict( dict, top, training_X, training_Y)\n",
    "    testing_X_selected, testing_Y = prepareDataset( test, dict_selected, updateDict=False,TEXT=label)\n",
    "    if freq == 0:\n",
    "        training_X_selected = training_X_selected.astype(bool).astype(int)\n",
    "        testing_X_selected = testing_X_selected.astype(bool).astype(int)\n",
    "    classifier = sklearn.naive_bayes.MultinomialNB()\n",
    "    classifier.fit( training_X_selected, training_Y )\n",
    "    testing_Y_pred = classifier.predict(testing_X_selected)\n",
    "    a = sklearn.metrics.accuracy_score( testing_Y, testing_Y_pred )\n",
    "    return a\n",
    "\n",
    "##train fold(2,3), test fold(1)\n",
    "uf, up, bf, bp, ubf, ubp = 0,0,0,0,0,0\n",
    "tr = fold2.append(fold3, ignore_index= True)\n",
    "ts = fold1\n",
    "uf  += accuracy(tr,ts,'unigrams',1,16165)\n",
    "up  += accuracy(tr,ts,'unigrams',0,16165)\n",
    "bf  += accuracy(tr,ts,'bigrams',1,16165)\n",
    "bp  += accuracy(tr,ts,'bigrams',0,16165)\n",
    "ubf  += accuracy(tr,ts,'unibigrams',1,16165)\n",
    "ubp  += accuracy(tr,ts,'unibigrams',0,16165)\n",
    "#print(uf,\" \",up,\" \",bf,\" \",bp,\" \",ubf,\" \",ubp)\n",
    "\n",
    "##train fold(1,3), test fold(2)\n",
    "tr = fold1.append(fold3, ignore_index= True)\n",
    "ts = fold2\n",
    "uf  += accuracy(tr,ts,'unigrams',1,16165)\n",
    "up  += accuracy(tr,ts,'unigrams',0,16165)\n",
    "bf  += accuracy(tr,ts,'bigrams',1,16165)\n",
    "bp  += accuracy(tr,ts,'bigrams',0,16165)\n",
    "ubf  += accuracy(tr,ts,'unibigrams',1,16165)\n",
    "ubp  += accuracy(tr,ts,'unibigrams',0,16165)\n",
    "#print(uf,\" \",up,\" \",bf,\" \",bp,\" \",ubf,\" \",ubp)\n",
    "\n",
    "##train fold(1,2), test fold(3)\n",
    "tr = fold1.append(fold2, ignore_index= True)\n",
    "ts = fold3\n",
    "uf  += accuracy(tr,ts,'unigrams',1,16165)\n",
    "up  += accuracy(tr,ts,'unigrams',0,16165)\n",
    "bf  += accuracy(tr,ts,'bigrams',1,16165)\n",
    "bp  += accuracy(tr,ts,'bigrams',0,16165)\n",
    "ubf  += accuracy(tr,ts,'unibigrams',1,16165)\n",
    "ubp  += accuracy(tr,ts,'unibigrams',0,16165)\n",
    "print(uf/3,\" \",up/3,\" \",bf/3,\" \",bp/3,\" \",ubf/3,\" \",ubp/3)\n",
    "\n",
    "feature,fp,accu,myacc = [],[],[],[]\n",
    "feature.append(\"Unigrams\")\n",
    "feature.append(\"Unigrams\")\n",
    "feature.append(\"Bigrams\")\n",
    "feature.append(\"Bigrams\")\n",
    "feature.append(\"Unigrams+Bigrams\")\n",
    "feature.append(\"Unigrams+Bigrams\")\n",
    "\n",
    "fp.append(\"Fres\")\n",
    "fp.append(\"Pres\")\n",
    "fp.append(\"Fres\")\n",
    "fp.append(\"Pres\")\n",
    "fp.append(\"Fres\")\n",
    "fp.append(\"Pres\")\n",
    "\n",
    "accu.append(0.7728)\n",
    "accu.append(0.7893)\n",
    "accu.append(0.7036)\n",
    "accu.append(0.6885)\n",
    "accu.append(0.7742)\n",
    "accu.append(0.7971)\n",
    "\n",
    "myacc.append(uf/3)\n",
    "myacc.append(up/3)\n",
    "myacc.append(bf/3)\n",
    "myacc.append(bp/3)\n",
    "myacc.append(ubf/3)\n",
    "myacc.append(ubp/3)\n",
    "\n",
    "final = pd.DataFrame()\n",
    "final['Features'] = feature\n",
    "final['Fres./Pres.'] = fp\n",
    "final['Accuracy'] = accu\n",
    "final['My Accuracy'] = myacc\n",
    "print(final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "466   466   468\n",
      "           Features Fres./Pres.  Accuracy  My Accuracy\n",
      "0          Unigrams        Fres    0.9900     0.989995\n",
      "1          Unigrams        Pres    0.9971     0.997142\n",
      "2           Bigrams        Fres    0.9979     0.997857\n",
      "3           Bigrams        Pres    0.9986     0.998569\n",
      "4  Unigrams+Bigrams        Fres    0.9964     0.992135\n",
      "5  Unigrams+Bigrams        Pres    0.9993     0.996427\n"
     ]
    }
   ],
   "source": [
    "#Settings 2\n",
    "##divide into k fold\n",
    "fold1 = data[data.fold == 1]\n",
    "fold2 = data[data.fold == 2]\n",
    "fold3 = data[data.fold == 3]\n",
    "print(len(fold1),\" \",len(fold2),\" \",len(fold3))\n",
    "\n",
    "def prepareDataset(data, dict, updateDict,TEXT):\n",
    "    X = dict.fit_transform( Counter(text) for text in data[TEXT] ) if updateDict else dict.transform( Counter(text) for text in data[TEXT] )\n",
    "    Y = np.array(data['label'])\n",
    "    return X, Y\n",
    "\n",
    "\n",
    "def select_dict( dict, top, X, Y ):\n",
    "    top = min( top, X.shape[1] )\n",
    "    fsel = feature_selection.SelectKBest( score_func = feature_selection.chi2, k = top )\n",
    "    X_selected = fsel.fit_transform( X, Y )\n",
    "    dict_selected = cp.deepcopy(dict).restrict( fsel.get_support() )\n",
    "    return dict_selected, X_selected\n",
    "\n",
    "\n",
    "\n",
    "def accuracy(trn,test,label,freq,n):\n",
    "    dict = DictVectorizer()\n",
    "    training_X, training_Y = prepareDataset(trn, dict, updateDict=True, TEXT=label)\n",
    "    #a = pd.DataFrame( training_X.toarray(), columns = dict.get_feature_names() )\n",
    "    top = int(n)\n",
    "    dict_selected, training_X_selected = select_dict( dict, top, training_X, training_Y)\n",
    "    testing_X_selected, testing_Y = prepareDataset( test, dict_selected, updateDict=False,TEXT=label)\n",
    "    #print(testing_X_selected.shape)\n",
    "    if freq == 0:\n",
    "        training_X_selected = training_X_selected.astype(bool).astype(int)\n",
    "        testing_X_selected = testing_X_selected.astype(bool).astype(int)\n",
    "    classifier = sklearn.naive_bayes.MultinomialNB()\n",
    "    classifier.fit( training_X_selected, training_Y )\n",
    "    testing_Y_pred = classifier.predict(testing_X_selected)\n",
    "    a = sklearn.metrics.accuracy_score( testing_Y, testing_Y_pred )\n",
    "    return a\n",
    "\n",
    "##train fold(1,2), test fold(1)\n",
    "uf, up, bf, bp, ubf, ubp = 0,0,0,0,0,0\n",
    "tr = fold1.append(fold2, ignore_index= True)\n",
    "ts = fold1\n",
    "uf  += accuracy(tr,ts,'unigrams',1,16165)\n",
    "up  += accuracy(tr,ts,'unigrams',0,16165)\n",
    "bf  += accuracy(tr,ts,'bigrams',1,16165)\n",
    "bp  += accuracy(tr,ts,'bigrams',0,16165)\n",
    "ubf  += accuracy(tr,ts,'unibigrams',1,16165)\n",
    "ubp  += accuracy(tr,ts,'unibigrams',0,16165)\n",
    "#print(uf,\" \",up,\" \",bf,\" \",bp,\" \",ubf,\" \",ubp)\n",
    "\n",
    "##train fold(2,3), test fold(2)\n",
    "tr = fold2.append(fold3, ignore_index= True)\n",
    "ts = fold2\n",
    "uf  += accuracy(tr,ts,'unigrams',1,16165)\n",
    "up  += accuracy(tr,ts,'unigrams',0,16165)\n",
    "bf  += accuracy(tr,ts,'bigrams',1,16165)\n",
    "bp  += accuracy(tr,ts,'bigrams',0,16165)\n",
    "ubf  += accuracy(tr,ts,'unibigrams',1,16165)\n",
    "ubp  += accuracy(tr,ts,'unibigrams',0,16165)\n",
    "#print(uf,\" \",up,\" \",bf,\" \",bp,\" \",ubf,\" \",ubp)\n",
    "\n",
    "##train fold(1,3), test fold(3)\n",
    "tr = fold1.append(fold3, ignore_index= True)\n",
    "ts = fold3\n",
    "uf  += accuracy(tr,ts,'unigrams',1,16165)\n",
    "up  += accuracy(tr,ts,'unigrams',0,16165)\n",
    "bf  += accuracy(tr,ts,'bigrams',1,16165)\n",
    "bp  += accuracy(tr,ts,'bigrams',0,16165)\n",
    "ubf  += accuracy(tr,ts,'unibigrams',1,16165)\n",
    "ubp  += accuracy(tr,ts,'unibigrams',0,16165)\n",
    "#print(uf/3,\" \",up/3,\" \",bf/3,\" \",bp/3,\" \",ubf/3,\" \",ubp/3)\n",
    "\n",
    "feature,fp,accu,myacc = [],[],[],[]\n",
    "feature.append(\"Unigrams\")\n",
    "feature.append(\"Unigrams\")\n",
    "feature.append(\"Bigrams\")\n",
    "feature.append(\"Bigrams\")\n",
    "feature.append(\"Unigrams+Bigrams\")\n",
    "feature.append(\"Unigrams+Bigrams\")\n",
    "\n",
    "fp.append(\"Fres\")\n",
    "fp.append(\"Pres\")\n",
    "fp.append(\"Fres\")\n",
    "fp.append(\"Pres\")\n",
    "fp.append(\"Fres\")\n",
    "fp.append(\"Pres\")\n",
    "\n",
    "accu.append(0.9900)\n",
    "accu.append(0.9971)\n",
    "accu.append(0.9979)\n",
    "accu.append(0.9986)\n",
    "accu.append(0.9964)\n",
    "accu.append(0.9993)\n",
    "\n",
    "myacc.append(uf/3)\n",
    "myacc.append(up/3)\n",
    "myacc.append(bf/3)\n",
    "myacc.append(bp/3)\n",
    "myacc.append(ubf/3)\n",
    "myacc.append(ubp/3)\n",
    "\n",
    "final = pd.DataFrame()\n",
    "final['Features'] = feature\n",
    "final['Fres./Pres.'] = fp\n",
    "final['Accuracy'] = accu\n",
    "final['My Accuracy'] = myacc\n",
    "print(final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "466   466   468\n",
      "           Features Fres./Pres.  Accuracy  My Accuracy\n",
      "0          Unigrams        Fres    0.9979     0.997142\n",
      "1          Unigrams        Pres    0.9993     0.999288\n",
      "2           Bigrams        Fres    1.0000     1.000000\n",
      "3           Bigrams        Pres    1.0000     1.000000\n",
      "4  Unigrams+Bigrams        Fres    0.9993     0.998569\n",
      "5  Unigrams+Bigrams        Pres    1.0000     0.999285\n"
     ]
    }
   ],
   "source": [
    "#Settings 3\n",
    "##divide into k fold\n",
    "fold1 = data[data.fold == 1]\n",
    "fold2 = data[data.fold == 2]\n",
    "fold3 = data[data.fold == 3]\n",
    "print(len(fold1),\" \",len(fold2),\" \",len(fold3))\n",
    "\n",
    "def prepareDataset(data, dict, updateDict,TEXT):\n",
    "    X = dict.fit_transform( Counter(text) for text in data[TEXT] ) if updateDict else dict.transform( Counter(text) for text in data[TEXT] )\n",
    "    Y = np.array(data['label'])\n",
    "    return X, Y\n",
    "\n",
    "\n",
    "def select_dict( dict, top, X, Y ):\n",
    "    top = min( top, X.shape[1] )\n",
    "    fsel = feature_selection.SelectKBest( score_func = feature_selection.chi2, k = top )\n",
    "    X_selected = fsel.fit_transform( X, Y )\n",
    "    dict_selected = cp.deepcopy(dict).restrict( fsel.get_support() )\n",
    "    return dict_selected, X_selected\n",
    "\n",
    "\n",
    "\n",
    "def accuracy(trn,test,label,freq,n):\n",
    "    dict = DictVectorizer()\n",
    "    training_X, training_Y = prepareDataset(trn, dict, updateDict=True, TEXT=label)\n",
    "    #a = pd.DataFrame( training_X.toarray(), columns = dict.get_feature_names() )\n",
    "    top = int(n)\n",
    "    dict_selected, training_X_selected = select_dict( dict, top, training_X, training_Y)\n",
    "    testing_X_selected, testing_Y = prepareDataset( test, dict_selected, updateDict=False,TEXT=label)\n",
    "    #print(testing_X_selected.shape)\n",
    "    if freq == 0:\n",
    "        training_X_selected = training_X_selected.astype(bool).astype(int)\n",
    "        testing_X_selected = testing_X_selected.astype(bool).astype(int)\n",
    "    classifier = sklearn.naive_bayes.MultinomialNB()\n",
    "    classifier.fit( training_X_selected, training_Y )\n",
    "    testing_Y_pred = classifier.predict(testing_X_selected)\n",
    "    a = sklearn.metrics.accuracy_score( testing_Y, testing_Y_pred )\n",
    "    return a\n",
    "\n",
    "##train fold(1), test fold(1)\n",
    "uf, up, bf, bp, ubf, ubp = 0,0,0,0,0,0\n",
    "tr = fold1\n",
    "ts = fold1\n",
    "uf  += accuracy(tr,ts,'unigrams',1,16165)\n",
    "up  += accuracy(tr,ts,'unigrams',0,16165)\n",
    "bf  += accuracy(tr,ts,'bigrams',1,16165)\n",
    "bp  += accuracy(tr,ts,'bigrams',0,16165)\n",
    "ubf  += accuracy(tr,ts,'unibigrams',1,16165)\n",
    "ubp  += accuracy(tr,ts,'unibigrams',0,16165)\n",
    "#print(uf,\" \",up,\" \",bf,\" \",bp,\" \",ubf,\" \",ubp)\n",
    "\n",
    "##train fold(2), test fold(2)\n",
    "tr = fold2\n",
    "ts = fold2\n",
    "uf  += accuracy(tr,ts,'unigrams',1,16165)\n",
    "up  += accuracy(tr,ts,'unigrams',0,16165)\n",
    "bf  += accuracy(tr,ts,'bigrams',1,16165)\n",
    "bp  += accuracy(tr,ts,'bigrams',0,16165)\n",
    "ubf  += accuracy(tr,ts,'unibigrams',1,16165)\n",
    "ubp  += accuracy(tr,ts,'unibigrams',0,16165)\n",
    "#print(uf,\" \",up,\" \",bf,\" \",bp,\" \",ubf,\" \",ubp)\n",
    "\n",
    "##train fold(3), test fold(3)\n",
    "tr = fold3\n",
    "ts = fold3\n",
    "uf  += accuracy(tr,ts,'unigrams',1,16165)\n",
    "up  += accuracy(tr,ts,'unigrams',0,16165)\n",
    "bf  += accuracy(tr,ts,'bigrams',1,16165)\n",
    "bp  += accuracy(tr,ts,'bigrams',0,16165)\n",
    "ubf  += accuracy(tr,ts,'unibigrams',1,16165)\n",
    "ubp  += accuracy(tr,ts,'unibigrams',0,16165)\n",
    "#print(uf/3,\" \",up/3,\" \",bf/3,\" \",bp/3,\" \",ubf/3,\" \",ubp/3)\n",
    "\n",
    "feature,fp,accu,myacc = [],[],[],[]\n",
    "feature.append(\"Unigrams\")\n",
    "feature.append(\"Unigrams\")\n",
    "feature.append(\"Bigrams\")\n",
    "feature.append(\"Bigrams\")\n",
    "feature.append(\"Unigrams+Bigrams\")\n",
    "feature.append(\"Unigrams+Bigrams\")\n",
    "\n",
    "fp.append(\"Fres\")\n",
    "fp.append(\"Pres\")\n",
    "fp.append(\"Fres\")\n",
    "fp.append(\"Pres\")\n",
    "fp.append(\"Fres\")\n",
    "fp.append(\"Pres\")\n",
    "\n",
    "accu.append(0.9979)\n",
    "accu.append(0.9993)\n",
    "accu.append(1.0000)\n",
    "accu.append(1.0000)\n",
    "accu.append(0.9993)\n",
    "accu.append(1.0000)\n",
    "\n",
    "myacc.append(uf/3)\n",
    "myacc.append(up/3)\n",
    "myacc.append(bf/3)\n",
    "myacc.append(bp/3)\n",
    "myacc.append(ubf/3)\n",
    "myacc.append(ubp/3)\n",
    "\n",
    "final = pd.DataFrame()\n",
    "final['Features'] = feature\n",
    "final['Fres./Pres.'] = fp\n",
    "final['Accuracy'] = accu\n",
    "final['My Accuracy'] = myacc\n",
    "print(final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "466   466   468\n",
      "0.736409155937053   0.7692766222809141   0.6485485981194136   0.6499547583238571   0.73140505973124   0.7471326559309391\n",
      "           Features Fres./Pres.  Accuracy  My Accuracy\n",
      "0          Unigrams        Fres    0.7307     0.736409\n",
      "1          Unigrams        Pres    0.7714     0.769277\n",
      "2           Bigrams        Fres    0.6485     0.648549\n",
      "3           Bigrams        Pres    0.6393     0.649955\n",
      "4  Unigrams+Bigrams        Fres    0.7321     0.731405\n",
      "5  Unigrams+Bigrams        Pres    0.7557     0.747133\n"
     ]
    }
   ],
   "source": [
    "#Settings 4\n",
    "##divide into k fold\n",
    "fold1 = data[data.fold == 1]\n",
    "fold2 = data[data.fold == 2]\n",
    "fold3 = data[data.fold == 3]\n",
    "print(len(fold1),\" \",len(fold2),\" \",len(fold3))\n",
    "\n",
    "def prepareDataset(data, dict, updateDict,TEXT):\n",
    "    X = dict.fit_transform( Counter(text) for text in data[TEXT] ) if updateDict else dict.transform( Counter(text) for text in data[TEXT] )\n",
    "    Y = np.array(data['label'])\n",
    "    return X, Y\n",
    "\n",
    "\n",
    "def select_dict( dict, top, X, Y ):\n",
    "    top = min( top, X.shape[1] )\n",
    "    fsel = feature_selection.SelectKBest( score_func = feature_selection.chi2, k = top )\n",
    "    X_selected = fsel.fit_transform( X, Y )\n",
    "    dict_selected = cp.deepcopy(dict).restrict( fsel.get_support() )\n",
    "    return dict_selected, X_selected\n",
    "\n",
    "\n",
    "\n",
    "def accuracy(trn,test,label,freq,n):\n",
    "    dict = DictVectorizer()\n",
    "    training_X, training_Y = prepareDataset(trn, dict, updateDict=True, TEXT=label)\n",
    "    #a = pd.DataFrame( training_X.toarray(), columns = dict.get_feature_names() )\n",
    "    top = int(n)\n",
    "    dict_selected, training_X_selected = select_dict( dict, top, training_X, training_Y)\n",
    "    testing_X_selected, testing_Y = prepareDataset( test, dict_selected, updateDict=False,TEXT=label)\n",
    "    #print(testing_X_selected.shape)\n",
    "    if freq == 0:\n",
    "        training_X_selected = training_X_selected.astype(bool).astype(int)\n",
    "        testing_X_selected = testing_X_selected.astype(bool).astype(int)\n",
    "    classifier = sklearn.naive_bayes.MultinomialNB()\n",
    "    classifier.fit( training_X_selected, training_Y )\n",
    "    testing_Y_pred = classifier.predict(testing_X_selected)\n",
    "    a = sklearn.metrics.accuracy_score( testing_Y, testing_Y_pred )\n",
    "    return a\n",
    "\n",
    "##train fold(2), test fold(1)\n",
    "uf, up, bf, bp, ubf, ubp = 0,0,0,0,0,0\n",
    "tr = fold2\n",
    "ts = fold1\n",
    "uf  += accuracy(tr,ts,'unigrams',1,16165)\n",
    "up  += accuracy(tr,ts,'unigrams',0,16165)\n",
    "bf  += accuracy(tr,ts,'bigrams',1,16165)\n",
    "bp  += accuracy(tr,ts,'bigrams',0,16165)\n",
    "ubf  += accuracy(tr,ts,'unibigrams',1,16165)\n",
    "ubp  += accuracy(tr,ts,'unibigrams',0,16165)\n",
    "#print(uf,\" \",up,\" \",bf,\" \",bp,\" \",ubf,\" \",ubp)\n",
    "\n",
    "##train fold(3), test fold(2)\n",
    "tr = fold3\n",
    "ts = fold2\n",
    "uf  += accuracy(tr,ts,'unigrams',1,16165)\n",
    "up  += accuracy(tr,ts,'unigrams',0,16165)\n",
    "bf  += accuracy(tr,ts,'bigrams',1,16165)\n",
    "bp  += accuracy(tr,ts,'bigrams',0,16165)\n",
    "ubf  += accuracy(tr,ts,'unibigrams',1,16165)\n",
    "ubp  += accuracy(tr,ts,'unibigrams',0,16165)\n",
    "#print(uf,\" \",up,\" \",bf,\" \",bp,\" \",ubf,\" \",ubp)\n",
    "\n",
    "##train fold(1), test fold(3)\n",
    "tr = fold1\n",
    "ts = fold3\n",
    "uf  += accuracy(tr,ts,'unigrams',1,16165)\n",
    "up  += accuracy(tr,ts,'unigrams',0,16165)\n",
    "bf  += accuracy(tr,ts,'bigrams',1,16165)\n",
    "bp  += accuracy(tr,ts,'bigrams',0,16165)\n",
    "ubf  += accuracy(tr,ts,'unibigrams',1,16165)\n",
    "ubp  += accuracy(tr,ts,'unibigrams',0,16165)\n",
    "print(uf/3,\" \",up/3,\" \",bf/3,\" \",bp/3,\" \",ubf/3,\" \",ubp/3)\n",
    "\n",
    "feature,fp,accu,myacc = [],[],[],[]\n",
    "feature.append(\"Unigrams\")\n",
    "feature.append(\"Unigrams\")\n",
    "feature.append(\"Bigrams\")\n",
    "feature.append(\"Bigrams\")\n",
    "feature.append(\"Unigrams+Bigrams\")\n",
    "feature.append(\"Unigrams+Bigrams\")\n",
    "\n",
    "fp.append(\"Fres\")\n",
    "fp.append(\"Pres\")\n",
    "fp.append(\"Fres\")\n",
    "fp.append(\"Pres\")\n",
    "fp.append(\"Fres\")\n",
    "fp.append(\"Pres\")\n",
    "\n",
    "accu.append(0.7307)\n",
    "accu.append(0.7714)\n",
    "accu.append(0.6485)\n",
    "accu.append(0.6393)\n",
    "accu.append(0.7321)\n",
    "accu.append(0.7557)\n",
    "\n",
    "myacc.append(uf/3)\n",
    "myacc.append(up/3)\n",
    "myacc.append(bf/3)\n",
    "myacc.append(bp/3)\n",
    "myacc.append(ubf/3)\n",
    "myacc.append(ubp/3)\n",
    "\n",
    "final = pd.DataFrame()\n",
    "final['Features'] = feature\n",
    "final['Fres./Pres.'] = fp\n",
    "final['Accuracy'] = accu\n",
    "final['My Accuracy'] = myacc\n",
    "print(final)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vg-U_41ya57u"
   },
   "source": [
    "## 4 Implement P2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "FOjvhpAXD8ow"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Features Fres./Pres.  Accuracy  My Accuracy\n",
      "0          Unigrams        Fres    0.7343     0.737828\n",
      "1          Unigrams        Pres    0.7671     0.754992\n",
      "2           Bigrams        Fres    0.6414     0.648549\n",
      "3           Bigrams        Pres    0.6443     0.645675\n",
      "4  Unigrams+Bigrams        Fres    0.7371     0.735697\n",
      "5  Unigrams+Bigrams        Pres    0.7572     0.765003\n"
     ]
    }
   ],
   "source": [
    "#Settings 5\n",
    "fold1 = data[data.fold == 1]\n",
    "fold2 = data[data.fold == 2]\n",
    "fold3 = data[data.fold == 3]\n",
    "\n",
    "def prepareDataset(data, dict, updateDict,TEXT):\n",
    "    X = dict.fit_transform( Counter(text) for text in data[TEXT] ) if updateDict else dict.transform( Counter(text) for text in data[TEXT] )\n",
    "    Y = np.array(data['label'])\n",
    "    return X, Y\n",
    "\n",
    "\n",
    "def select_dict( dict, top, X, Y ):\n",
    "    top = min( top, X.shape[1] )\n",
    "    fsel = feature_selection.SelectKBest( score_func = feature_selection.chi2, k = top )\n",
    "    X_selected = fsel.fit_transform( X, Y )\n",
    "    dict_selected = cp.deepcopy(dict).restrict( fsel.get_support() )\n",
    "    return dict_selected, X_selected\n",
    "\n",
    "\n",
    "def accuracy(trn,test,label,freq,n):\n",
    "    dict = DictVectorizer()\n",
    "    training_X, training_Y = prepareDataset(trn, dict, updateDict=True, TEXT=label)\n",
    "    #a = pd.DataFrame( training_X.toarray(), columns = dict.get_feature_names() )\n",
    "    top = int(n)\n",
    "    dict_selected, training_X_selected = select_dict( dict, top, training_X, training_Y)\n",
    "    testing_X_selected, testing_Y = prepareDataset( test, dict_selected, updateDict=False,TEXT=label)\n",
    "    #print(testing_X_selected.shape)\n",
    "    if freq == 0:\n",
    "        training_X_selected = training_X_selected.astype(bool).astype(int)\n",
    "        testing_X_selected = testing_X_selected.astype(bool).astype(int)\n",
    "    classifier = sklearn.naive_bayes.MultinomialNB()\n",
    "    classifier.fit( training_X_selected, training_Y )\n",
    "    testing_Y_pred = classifier.predict(testing_X_selected)\n",
    "    a = sklearn.metrics.accuracy_score( testing_Y, testing_Y_pred )\n",
    "    return a\n",
    "\n",
    "def findk(tr,vl,label,fres):\n",
    "    mxa = 0.00\n",
    "    mxk = 2000\n",
    "    k = 2000\n",
    "    while k <= 20000:\n",
    "        a = accuracy(tr,vl,label,fres,k)\n",
    "        if a >= mxa:\n",
    "            mxk = k\n",
    "            mxa = a\n",
    "        k += 2000\n",
    "    return mxk\n",
    "\n",
    "\n",
    "tr,ts,vl = fold2,fold1,fold3\n",
    "uf, up, bf, bp, ubf, ubp = 0,0,0,0,0,0\n",
    "k = findk(tr,vl,\"unigrams\",1)\n",
    "uf += accuracy(tr,ts,'unigrams',1,k)\n",
    "\n",
    "k = findk(tr,vl,\"unigrams\",0)\n",
    "up += accuracy(tr,ts,'unigrams',0,k)\n",
    "\n",
    "k = findk(tr,vl,\"bigrams\",1)\n",
    "bf += accuracy(tr,ts,'bigrams',1,k)\n",
    "\n",
    "k = findk(tr,vl,\"bigrams\",0)\n",
    "bp += accuracy(tr,ts,'bigrams',0,k)\n",
    "\n",
    "k = findk(tr,vl,\"unibigrams\",1)\n",
    "ubf += accuracy(tr,ts,'unibigrams',1,k)\n",
    "\n",
    "k = findk(tr,vl,\"unibigrams\",0)\n",
    "ubp += accuracy(tr,ts,'unibigrams',0,k)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "tr,ts,vl = fold3,fold2,fold1\n",
    "k = findk(tr,vl,\"unigrams\",1)\n",
    "uf += accuracy(tr,ts,'unigrams',1,k)\n",
    "\n",
    "k = findk(tr,vl,\"unigrams\",0)\n",
    "up += accuracy(tr,ts,'unigrams',0,k)\n",
    "\n",
    "k = findk(tr,vl,\"bigrams\",1)\n",
    "bf += accuracy(tr,ts,'bigrams',1,k)\n",
    "\n",
    "k = findk(tr,vl,\"bigrams\",0)\n",
    "bp += accuracy(tr,ts,'bigrams',0,k)\n",
    "\n",
    "k = findk(tr,vl,\"unibigrams\",1)\n",
    "ubf += accuracy(tr,ts,'unibigrams',1,k)\n",
    "\n",
    "k = findk(tr,vl,\"unibigrams\",0)\n",
    "ubp += accuracy(tr,ts,'unibigrams',0,k)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "tr,ts,vl = fold1,fold3,fold2\n",
    "k = findk(tr,vl,\"unigrams\",1)\n",
    "uf += accuracy(tr,ts,'unigrams',1,k)\n",
    "\n",
    "k = findk(tr,vl,\"unigrams\",0)\n",
    "up += accuracy(tr,ts,'unigrams',0,k)\n",
    "\n",
    "k = findk(tr,vl,\"bigrams\",1)\n",
    "bf += accuracy(tr,ts,'bigrams',1,k)\n",
    "\n",
    "k = findk(tr,vl,\"bigrams\",0)\n",
    "bp += accuracy(tr,ts,'bigrams',0,k)\n",
    "\n",
    "k = findk(tr,vl,\"unibigrams\",1)\n",
    "ubf += accuracy(tr,ts,'unibigrams',1,k)\n",
    "\n",
    "k = findk(tr,vl,\"unibigrams\",0)\n",
    "ubp += accuracy(tr,ts,'unibigrams',0,k)\n",
    "\n",
    "\n",
    "feature,fp,accu,myacc = [],[],[],[]\n",
    "feature.append(\"Unigrams\")\n",
    "feature.append(\"Unigrams\")\n",
    "feature.append(\"Bigrams\")\n",
    "feature.append(\"Bigrams\")\n",
    "feature.append(\"Unigrams+Bigrams\")\n",
    "feature.append(\"Unigrams+Bigrams\")\n",
    "\n",
    "fp.append(\"Fres\")\n",
    "fp.append(\"Pres\")\n",
    "fp.append(\"Fres\")\n",
    "fp.append(\"Pres\")\n",
    "fp.append(\"Fres\")\n",
    "fp.append(\"Pres\")\n",
    "\n",
    "accu.append(0.7343)\n",
    "accu.append(0.7671)\n",
    "accu.append(0.6414)\n",
    "accu.append(0.6443)\n",
    "accu.append(0.7371)\n",
    "accu.append(0.7572)\n",
    "\n",
    "myacc.append(uf/3)\n",
    "myacc.append(up/3)\n",
    "myacc.append(bf/3)\n",
    "myacc.append(bp/3)\n",
    "myacc.append(ubf/3)\n",
    "myacc.append(ubp/3)\n",
    "\n",
    "final = pd.DataFrame()\n",
    "final['Features'] = feature\n",
    "final['Fres./Pres.'] = fp\n",
    "final['Accuracy'] = accu\n",
    "final['My Accuracy'] = myacc\n",
    "print(final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best k  10000\n",
      "best k  20000\n",
      "best k  20000\n",
      "best k  20000\n",
      "best k  4000\n",
      "best k  6000\n",
      "best k  20000\n",
      "best k  10000\n",
      "best k  16000\n",
      "best k  20000\n",
      "best k  20000\n",
      "best k  12000\n",
      "best k  4000\n",
      "best k  8000\n",
      "best k  18000\n",
      "best k  16000\n",
      "best k  8000\n",
      "best k  8000\n",
      "           Features Fres./Pres.  Accuracy  My Accuracy\n",
      "0          Unigrams        Fres    0.7428     0.745696\n",
      "1          Unigrams        Pres    0.7764     0.776421\n",
      "2           Bigrams        Fres    0.6521     0.652125\n",
      "3           Bigrams        Pres    0.6471     0.651388\n",
      "4  Unigrams+Bigrams        Fres    0.7400     0.738546\n",
      "5  Unigrams+Bigrams        Pres    0.7700     0.770713\n"
     ]
    }
   ],
   "source": [
    "#Settings 6\n",
    "fold1 = data[data.fold == 1]\n",
    "fold2 = data[data.fold == 2]\n",
    "fold3 = data[data.fold == 3]\n",
    "\n",
    "def prepareDataset(data, dict, updateDict,TEXT):\n",
    "    X = dict.fit_transform( Counter(text) for text in data[TEXT] ) if updateDict else dict.transform( Counter(text) for text in data[TEXT] )\n",
    "    Y = np.array(data['label'])\n",
    "    return X, Y\n",
    "\n",
    "\n",
    "def select_dict( dict, top, X, Y ):\n",
    "    top = min( top, X.shape[1] )\n",
    "    fsel = feature_selection.SelectKBest( score_func = feature_selection.chi2, k = top )\n",
    "    X_selected = fsel.fit_transform( X, Y )\n",
    "    dict_selected = cp.deepcopy(dict).restrict( fsel.get_support() )\n",
    "    return dict_selected, X_selected\n",
    "\n",
    "\n",
    "def accuracy(trn,test,label,freq,n):\n",
    "    dict = DictVectorizer()\n",
    "    training_X, training_Y = prepareDataset(trn, dict, updateDict=True, TEXT=label)\n",
    "    #a = pd.DataFrame( training_X.toarray(), columns = dict.get_feature_names() )\n",
    "    top = int(n)\n",
    "    dict_selected, training_X_selected = select_dict( dict, top, training_X, training_Y)\n",
    "    testing_X_selected, testing_Y = prepareDataset( test, dict_selected, updateDict=False,TEXT=label)\n",
    "    #print(testing_X_selected.shape)\n",
    "    if freq == 0:\n",
    "        training_X_selected = training_X_selected.astype(bool).astype(int)\n",
    "        testing_X_selected = testing_X_selected.astype(bool).astype(int)\n",
    "    classifier = sklearn.naive_bayes.MultinomialNB()\n",
    "    classifier.fit( training_X_selected, training_Y )\n",
    "    testing_Y_pred = classifier.predict(testing_X_selected)\n",
    "    a = sklearn.metrics.accuracy_score( testing_Y, testing_Y_pred )\n",
    "    return a\n",
    "\n",
    "def findk(tr,vl,label,fres):\n",
    "    mxa = 0.00\n",
    "    mxk = 2000\n",
    "    k = 2000\n",
    "    while k <= 20000:\n",
    "        a = accuracy(tr,vl,label,fres,k)\n",
    "        if a >= mxa:\n",
    "            mxk = k\n",
    "            mxa = a\n",
    "        k += 2000\n",
    "    print(\"best k \",mxk)\n",
    "    return mxk\n",
    "\n",
    "\n",
    "tr,ts,vl = fold2,fold1,fold1\n",
    "uf, up, bf, bp, ubf, ubp = 0,0,0,0,0,0\n",
    "k = findk(tr,vl,\"unigrams\",1)\n",
    "uf += accuracy(tr,ts,'unigrams',1,k)\n",
    "\n",
    "k = findk(tr,vl,\"unigrams\",0)\n",
    "up += accuracy(tr,ts,'unigrams',0,k)\n",
    "\n",
    "k = findk(tr,vl,\"bigrams\",1)\n",
    "bf += accuracy(tr,ts,'bigrams',1,k)\n",
    "\n",
    "k = findk(tr,vl,\"bigrams\",0)\n",
    "bp += accuracy(tr,ts,'bigrams',0,k)\n",
    "\n",
    "k = findk(tr,vl,\"unibigrams\",1)\n",
    "ubf += accuracy(tr,ts,'unibigrams',1,k)\n",
    "\n",
    "k = findk(tr,vl,\"unibigrams\",0)\n",
    "ubp += accuracy(tr,ts,'unibigrams',0,k)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "tr,ts,vl = fold3,fold2,fold2\n",
    "k = findk(tr,vl,\"unigrams\",1)\n",
    "uf += accuracy(tr,ts,'unigrams',1,k)\n",
    "\n",
    "k = findk(tr,vl,\"unigrams\",0)\n",
    "up += accuracy(tr,ts,'unigrams',0,k)\n",
    "\n",
    "k = findk(tr,vl,\"bigrams\",1)\n",
    "bf += accuracy(tr,ts,'bigrams',1,k)\n",
    "\n",
    "k = findk(tr,vl,\"bigrams\",0)\n",
    "bp += accuracy(tr,ts,'bigrams',0,k)\n",
    "\n",
    "k = findk(tr,vl,\"unibigrams\",1)\n",
    "ubf += accuracy(tr,ts,'unibigrams',1,k)\n",
    "\n",
    "k = findk(tr,vl,\"unibigrams\",0)\n",
    "ubp += accuracy(tr,ts,'unibigrams',0,k)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "tr,ts,vl = fold1,fold3,fold3\n",
    "k = findk(tr,vl,\"unigrams\",1)\n",
    "uf += accuracy(tr,ts,'unigrams',1,k)\n",
    "\n",
    "k = findk(tr,vl,\"unigrams\",0)\n",
    "up += accuracy(tr,ts,'unigrams',0,k)\n",
    "\n",
    "k = findk(tr,vl,\"bigrams\",1)\n",
    "bf += accuracy(tr,ts,'bigrams',1,k)\n",
    "\n",
    "k = findk(tr,vl,\"bigrams\",0)\n",
    "bp += accuracy(tr,ts,'bigrams',0,k)\n",
    "\n",
    "k = findk(tr,vl,\"unibigrams\",1)\n",
    "ubf += accuracy(tr,ts,'unibigrams',1,k)\n",
    "\n",
    "k = findk(tr,vl,\"unibigrams\",0)\n",
    "ubp += accuracy(tr,ts,'unibigrams',0,k)\n",
    "\n",
    "\n",
    "feature,fp,accu,myacc = [],[],[],[]\n",
    "feature.append(\"Unigrams\")\n",
    "feature.append(\"Unigrams\")\n",
    "feature.append(\"Bigrams\")\n",
    "feature.append(\"Bigrams\")\n",
    "feature.append(\"Unigrams+Bigrams\")\n",
    "feature.append(\"Unigrams+Bigrams\")\n",
    "\n",
    "fp.append(\"Fres\")\n",
    "fp.append(\"Pres\")\n",
    "fp.append(\"Fres\")\n",
    "fp.append(\"Pres\")\n",
    "fp.append(\"Fres\")\n",
    "fp.append(\"Pres\")\n",
    "\n",
    "accu.append(0.7428)\n",
    "accu.append(0.7764)\n",
    "accu.append(0.6521)\n",
    "accu.append(0.6471)\n",
    "accu.append(0.7400)\n",
    "accu.append(0.7700)\n",
    "\n",
    "myacc.append(uf/3)\n",
    "myacc.append(up/3)\n",
    "myacc.append(bf/3)\n",
    "myacc.append(bp/3)\n",
    "myacc.append(ubf/3)\n",
    "myacc.append(ubp/3)\n",
    "\n",
    "final = pd.DataFrame()\n",
    "final['Features'] = feature\n",
    "final['Fres./Pres.'] = fp\n",
    "final['Accuracy'] = accu\n",
    "final['My Accuracy'] = myacc\n",
    "print(final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "hw3.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
